{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The smart data analysis assistant "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File system and data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path datasets already exists\n"
     ]
    }
   ],
   "source": [
    "data_dir = path.Path(\"datasets\")\n",
    "if not data_dir.exists:\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "else :\n",
    "    print(\"Path {} already exists\".format(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validate input. Returns boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# read in excel or csv file\n",
    "def validate_file(source):\n",
    "    if path.Path(source).is_file():\n",
    "        if path.Path(source).suffix in [\".csv\",\".xlsx\"]:\n",
    "            print(\"file is valid\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"unaccepted file format\")\n",
    "            print(path.Path(source).suffix)\n",
    "            return False\n",
    "    else:\n",
    "        print(\"file is invalid\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read input. Returns tuple (dataframe/None,source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset if valid\n",
    "import pandas as pd\n",
    "def read_input(source):\n",
    "    is_valid = validate_file(source)\n",
    "    if is_valid:\n",
    "        if path.Path(source).suffix == \".csv\":\n",
    "            data = pd.read_csv(source)\n",
    "            return (data,source)\n",
    "\n",
    "        elif path.Path(source).suffix == \".xlsx\":\n",
    "            data = pd.read_excel(source)\n",
    "            return (data,source)\n",
    "    return (None,source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test read_input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is invalid\n",
      "Provide file '  ' in ivalid\n"
     ]
    }
   ],
   "source": [
    "#read invalid file\n",
    "res = read_input(\"\")\n",
    "if res[0] is None:\n",
    "    print(\"Provide file ' {} ' in ivalid\".format(res[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is valid\n",
      "file '../Datasets/pima-indians-diabetes.csv' is valid\n"
     ]
    }
   ],
   "source": [
    "#read valid file\n",
    "res = read_input(\"../Datasets/pima-indians-diabetes.csv\")\n",
    "print(\"file '{}' is valid\".format(res[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grab dataframe as first item in tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trying to describe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_data(data):\n",
    "    if len(data) > 0:\n",
    "        # Take a peep at the data\n",
    "        print(\"Take a peep ...\")\n",
    "        print(data.head())\n",
    "\n",
    "        print(\"Datatypes in dataset ...\")\n",
    "        #Get data types\n",
    "        print(data.dtypes)\n",
    "\n",
    "        print(\"Columns in dataset ...\")\n",
    "        #Get columns\n",
    "        print(data.columns)\n",
    "\n",
    "        print(\"Shape of dataset ...\")\n",
    "        #Get shape of data\n",
    "        shape = data.shape\n",
    "        print(\"Dataset has {} rows and {} columns\".format(shape[0],shape[1]))\n",
    "\n",
    "        print(\"Describe dataset ...\")\n",
    "        #Descriptive summary\n",
    "        print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take a peep ...\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "Datatypes in dataset ...\n",
      "Pregnancies                   int64\n",
      "Glucose                       int64\n",
      "BloodPressure                 int64\n",
      "SkinThickness                 int64\n",
      "Insulin                       int64\n",
      "BMI                         float64\n",
      "DiabetesPedigreeFunction    float64\n",
      "Age                           int64\n",
      "Outcome                       int64\n",
      "dtype: object\n",
      "Columns in dataset ...\n",
      "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
      "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
      "      dtype='object')\n",
      "Shape of dataset ...\n",
      "Dataset has 768 rows and 9 columns\n",
      "Describe dataset ...\n",
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Lets describe the dataset \n",
    "describe_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric fields\n",
    "numeric_data = data.select_dtypes(exclude=['O','bool'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take a peep ...\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "Datatypes in dataset ...\n",
      "Pregnancies                   int64\n",
      "Glucose                       int64\n",
      "BloodPressure                 int64\n",
      "SkinThickness                 int64\n",
      "Insulin                       int64\n",
      "BMI                         float64\n",
      "DiabetesPedigreeFunction    float64\n",
      "Age                           int64\n",
      "Outcome                       int64\n",
      "dtype: object\n",
      "Columns in dataset ...\n",
      "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
      "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
      "      dtype='object')\n",
      "Shape of dataset ...\n",
      "Dataset has 768 rows and 9 columns\n"
     ]
    }
   ],
   "source": [
    "describe_data(numeric_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe numeric data\n",
    "#numeric_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to get null value statistics from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What fields have  null values\n",
    "\n",
    "def get_null_stats(data):\n",
    "    \n",
    "    #What is the percentage of these null values \n",
    "    null_fields = get_null_fields(data)[0]\n",
    "    null_fields_names = get_null_fields(data)[1]\n",
    "\n",
    "    for col in null_fields_names:\n",
    "        null_fields[col] = null_fields[col]*100/len(data[col])\n",
    "\n",
    "    return null_fields\n",
    "\n",
    "\n",
    "def get_null_fields(data):\n",
    "    null_stats = data.isnull().sum()\n",
    "    null_fields = null_stats[null_stats>0]\n",
    "    null_fields\n",
    "    #What is the percentage of these null values \n",
    "    null_fields_names = null_fields.index\n",
    "\n",
    "    return (null_fields,null_fields_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get summary and next step suggestions on any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_summary(null_stats):\n",
    "    nulls_exist = len(null_stats) > 0\n",
    "    if nulls_exist:\n",
    "        print(\"dataset has null numeric values\")\n",
    "        print(\"........\")\n",
    "        print(\"summary\")\n",
    "        print(\"...................\")\n",
    "        print(null_stats)\n",
    "        print(\"...................\")\n",
    "        print(\"...................\")\n",
    "        print(\"\"\"Possible actions to take :\n",
    "            1. Drop rows with any missing values\n",
    "            2. Drop columns with miissing values\n",
    "            3. Inpute missing data\n",
    "            \"\"\")\n",
    "    else:\n",
    "        print(\"dataset has no null values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use functions to get null statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has no null values\n"
     ]
    }
   ],
   "source": [
    "# Get null stats\n",
    "numeric_data_null_stats = get_null_stats(numeric_data)\n",
    "\n",
    "# Print summary based on null stats\n",
    "print_summary(numeric_data_null_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define null remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer(columns):\n",
    "    print('impute missing data in colums {}'.format(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_remover(decision,df,columns=[]):\n",
    "    if decision == \"drop_rows\":\n",
    "       cleaned = df.dropna(axis=0)\n",
    "       \n",
    "       print(\"Dropped {} rows from dataset\".format(len(df)-len(cleaned)))\n",
    "       print(\"...................\")\n",
    "\n",
    "    elif decision == \"drop_cols\":\n",
    "       if len(columns) == 0:\n",
    "           print(\"Please provide a nonempty column list\")\n",
    "           print(\"...................\")\n",
    "\n",
    "       cleaned = df.drop(columns,axis=1)\n",
    "       print(\"Dropped columns {} from dataset\".format(columns))\n",
    "       print(\"...................\")\n",
    "\n",
    "\n",
    "    elif decision == \"inpute\":\n",
    "        imputer(columns)\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use null remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide a nonempty column list\n",
      "...................\n",
      "Dropped columns Index([], dtype='object') from dataset\n",
      "...................\n",
      "Pregnancies                 False\n",
      "Glucose                     False\n",
      "BloodPressure               False\n",
      "SkinThickness               False\n",
      "Insulin                     False\n",
      "BMI                         False\n",
      "DiabetesPedigreeFunction    False\n",
      "Age                         False\n",
      "Outcome                     False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets deal with null values for numeric data\n",
    "cleaned = null_remover(\"drop_cols\",numeric_data,get_null_fields(numeric_data)[1])\n",
    "print(cleaned.isnull().any())\n",
    "cleaned.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows from dataset\n",
      "...................\n",
      "Pregnancies                 False\n",
      "Glucose                     False\n",
      "BloodPressure               False\n",
      "SkinThickness               False\n",
      "Insulin                     False\n",
      "BMI                         False\n",
      "DiabetesPedigreeFunction    False\n",
      "Age                         False\n",
      "Outcome                     False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets deal with null values\n",
    "cleaned = null_remover(\"drop_rows\",numeric_data)\n",
    "print(cleaned.isnull().any())\n",
    "cleaned.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_data = data.select_dtypes(exclude=['int64','float64'])\n",
    "categorical_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot describe a DataFrame without columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/macbook/Documents/AI-LAB/DataAnalysis/Analyst.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/macbook/Documents/AI-LAB/DataAnalysis/Analyst.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m categorical_data\u001b[39m.\u001b[39;49mdescribe()\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv-env/lib/python3.11/site-packages/pandas/core/generic.py:11537\u001b[0m, in \u001b[0;36mNDFrame.describe\u001b[0;34m(self, percentiles, include, exclude)\u001b[0m\n\u001b[1;32m  11295\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m  11296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdescribe\u001b[39m(\n\u001b[1;32m  11297\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11300\u001b[0m     exclude\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m  11301\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Self:\n\u001b[1;32m  11302\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m  11303\u001b[0m \u001b[39m    Generate descriptive statistics.\u001b[39;00m\n\u001b[1;32m  11304\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11535\u001b[0m \u001b[39m    max            NaN      3.0\u001b[39;00m\n\u001b[1;32m  11536\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m> 11537\u001b[0m     \u001b[39mreturn\u001b[39;00m describe_ndframe(\n\u001b[1;32m  11538\u001b[0m         obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m  11539\u001b[0m         include\u001b[39m=\u001b[39;49minclude,\n\u001b[1;32m  11540\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m  11541\u001b[0m         percentiles\u001b[39m=\u001b[39;49mpercentiles,\n\u001b[1;32m  11542\u001b[0m     )\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdescribe\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv-env/lib/python3.11/site-packages/pandas/core/methods/describe.py:91\u001b[0m, in \u001b[0;36mdescribe_ndframe\u001b[0;34m(obj, include, exclude, percentiles)\u001b[0m\n\u001b[1;32m     87\u001b[0m     describer \u001b[39m=\u001b[39m SeriesDescriber(\n\u001b[1;32m     88\u001b[0m         obj\u001b[39m=\u001b[39mcast(\u001b[39m\"\u001b[39m\u001b[39mSeries\u001b[39m\u001b[39m\"\u001b[39m, obj),\n\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     90\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     describer \u001b[39m=\u001b[39m DataFrameDescriber(\n\u001b[1;32m     92\u001b[0m         obj\u001b[39m=\u001b[39;49mcast(\u001b[39m\"\u001b[39;49m\u001b[39mDataFrame\u001b[39;49m\u001b[39m\"\u001b[39;49m, obj),\n\u001b[1;32m     93\u001b[0m         include\u001b[39m=\u001b[39;49minclude,\n\u001b[1;32m     94\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m     95\u001b[0m     )\n\u001b[1;32m     97\u001b[0m result \u001b[39m=\u001b[39m describer\u001b[39m.\u001b[39mdescribe(percentiles\u001b[39m=\u001b[39mpercentiles)\n\u001b[1;32m     98\u001b[0m \u001b[39mreturn\u001b[39;00m cast(NDFrameT, result)\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv-env/lib/python3.11/site-packages/pandas/core/methods/describe.py:160\u001b[0m, in \u001b[0;36mDataFrameDescriber.__init__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexclude \u001b[39m=\u001b[39m exclude\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m obj\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m obj\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot describe a DataFrame without columns\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    162\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(obj)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot describe a DataFrame without columns"
     ]
    }
   ],
   "source": [
    "categorical_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has no null values\n"
     ]
    }
   ],
   "source": [
    "# Get null stats for categorical data\n",
    "categorical_data_null_stats = get_null_stats(categorical_data)\n",
    "\n",
    "print_summary(categorical_data_null_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has no null values\n"
     ]
    }
   ],
   "source": [
    "# Get null stats for whole dataset\n",
    "\n",
    "data_null_stats = get_null_stats(data)\n",
    "\n",
    "print_summary(data_null_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
